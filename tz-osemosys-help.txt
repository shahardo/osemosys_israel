Help on class Model in module tz.osemosys.model.model:

class Model(tz.osemosys.schemas.model.RunSpec)
 |  Model(*, otoole_cfg: tz.osemosys.schemas.compat.base.OtooleCfg | None = None, defaults_otoole: tz.osemosys.schemas.compat.base.DefaultsOtoole | None = None, id: str, long_name: str, description: str, time_definition: tz.osemosys.schemas.time_definition.TimeDefinition, regions: List[tz.osemosys.schemas.region.Region], regionsgroup: Optional[List[tz.osemosys.schemas.region.RegionGroup]] = None, commodities: List[tz.osemosys.schemas.commodity.Commodity], impacts: List[tz.osemosys.schemas.impact.Impact], technologies: List[tz.osemosys.schemas.technology.Technology], trade: Optional[List[tz.osemosys.schemas.trade.Trade]] = None, storage: Optional[List[tz.osemosys.schemas.storage.Storage]] = None, depreciation_method: tz.osemosys.schemas.base.OSeMOSYSData_R_DM = OSeMOSYSData_R_DM(is_composed=False, data=<DepreciationMethod.sinking_fund: 'sinking-fund'>), cost_of_capital: tz.osemosys.schemas.base.OSeMOSYSData_RT | None = None, cost_of_capital_storage: tz.osemosys.schemas.base.OSeMOSYSData_RO | None = None, discount_rate: tz.osemosys.schemas.base.OSeMOSYSData_R = OSeMOSYSData_R(is_composed=False, data=0.05), reserve_margin: tz.osemosys.schemas.base.OSeMOSYSData_RY = OSeMOSYSData_RY(is_composed=False, data=1.0), renewable_production_target: tz.osemosys.schemas.base.OSeMOSYSData_RY | None = None, region_group_renewable_production_target: tz.osemosys.schemas.base.OSeMOSYSData_GY | None = None) -> None
 |
 |  # Model
 |
 |  The Model class contains all data required to run a TZ-OSeMOSYS model, spread across subclasses,
 |  along with class methods for loading/constructing and solving a model.
 |
 |  ## Parameters
 |
 |  `id` `(str)`: Used to represent the name of the OSeMOSYS model.
 |  Required parameter.
 |
 |  `time_definition` `(TimeDefinition)` - Single TimeDefinition class instance to contain all
 |  temporal data related to the model. Required parameter.
 |
 |  `regions` `(List[Region])` - List of Region instances to contain region names.
 |  Required parameter.
 |
 |  `regionsgroup` `(List[RegionGroup])` - List of Region Group instances to contain region group
 |  names.
 |  Optional parameter, defaults to `None`.
 |
 |  `commodities` `(List[Commodity])` - List of Commodity instances to contain all data related to
 |  commodities (OSeMOSYS FUEL).
 |  Required parameter.
 |
 |  `impacts` `(List[Impact])` - List of Impact instances to contain all data related to impacts
 |  (OSeMOSYS EMISSION).
 |  Required parameter.
 |
 |  `technologies` `(List[Technology])` - List of Technology instances to contain all data
 |  related to technologies.
 |  Required parameter.
 |
 |  `storage` `(List[Storage])` - List of Storage instances to contain all data related to storage.
 |  Optional parameter, defaults to `None`.
 |
 |  `trade` `(List[Trade])` - List of Trade instances to contain all data related to trade routes.
 |  Optional parameter, defaults to `None`.
 |
 |  `depreciation_method` `({region:str})` - OSeMOSYS DepreciationMethod.
 |  Parameter defining the type of depreciation to be applied, must take values of 'sinking-fund' or
 |  'straight-line'.
 |  Optional parameter, defaults to 'sinking-fund'.
 |
 |  `discount_rate` `({region:float})` - OSeMOSYS DiscountRate.
 |  Region specific value for the discount rate.
 |  Optional parameter, defaults to 0.05.
 |
 |  `cost_of_capital` `({region:{technology:float}})` - OSeMOSYS DiscountRateIdv.
 |  Discount rate specified by region and technology.
 |  Optional parameter, defaults to `None`.
 |
 |  `cost_of_capital_storage` `({region:{storage:float}})` - OSeMOSYS DiscountRateStorage.
 |  Discount rate specified by region and storage.
 |  Optional parameter, defaults to `None`.
 |
 |  `cost_of_capital_trade` `({region:{region:{commodity:float}}})` - Parameter additional to
 |  OSeMOSYS base variables. Discount rate specified for trade (transmission) technologies.
 |  Optional parameter, defaults to `None`.
 |
 |  `reserve_margin` `({region:{year:float}})` - OSeMOSYS ReserveMargin.
 |  Minimum level of the reserve margin required to be provided for all the tagged commodities, by
 |  the tagged technologies. If no reserve margin is required, the parameter will have value 1; if,
 |  for instance, 20% reserve margin is required, the parameter will have value 1.2.
 |  Optional parameter, defaults to 1.
 |
 |  `renewable_production_target` `({region:{year:float}})` - OSeMOSYS REMinProductionTarget.
 |  Minimum ratio of all renewable commodities tagged in the
 |  include_in_joint_renewable_target parameter, to be
 |  produced by the technologies tagged with the include_in_joint_renewable_target parameter.
 |  Optional parameter, defaults to `None`.
 |
 |  ## Loading/constructing a model
 |
 |  ### From dicts
 |
 |  A simple example of how a Model object might be created directly from provided data is below:
 |
 |  ```python
 |  from tz.osemosys import (
 |      Model,
 |      Technology,
 |      TimeDefinition,
 |      Commodity,
 |      Region,
 |      RegionGroup,
 |      Impact,
 |      OperatingMode,
 |  )
 |
 |  time_definition = TimeDefinition(id="years-only", years=range(2020, 2051))
 |  regions = [Region(id="single-region")]
 |  commodities = [Commodity(id="electricity", demand_annual=25 * 8760)]  # 25GW * 8760hr/yr
 |  impacts = [Impact(id="CO2", penalty=60)]  # 60 $mn/Mtonne
 |  technologies = [
 |      Technology(
 |          id="coal-gen",
 |          operating_life=40,  # years
 |          capex=800,  # mn$/GW
 |          # straight-line reduction to 2040
 |          residual_capacity={
 |              yr: 25 * max((1 - (yr - 2020) / (2040 - 2020), 0))
 |              for yr in range(2020, 2051)
 |          },
 |          operating_modes=[
 |              OperatingMode(
 |                  id="generation",
 |                  # $mn20/Mt.coal / 8.14 TWh/Mt coal * 8760 GWh/GW / 0.3 /1000 GWh/TWh (therm eff)
 |                  opex_variable=20 / 8.14 * 8760 / 0.3 / 1000,  # $71/GW/yr
 |                  output_activity_ratio={"electricity": 1.0 * 8760},  # GWh/yr/GW
 |                  emission_activity_ratio={
 |                      "CO2": 0.354 * 8760 / 1000
 |                  },  # Mtco2/TWh * 8760GWh/Gw/yr /1000 GWh/TWh
 |              )
 |          ],
 |      ),
 |      Technology(
 |          id="solar-pv",
 |          operating_life=25,
 |          capex=1200,
 |          capacity_factor=0.3,
 |          operating_modes=[
 |              OperatingMode(
 |                  id="generation",
 |                  opex_variable=0,
 |                  output_activity_ratio={"electricity": 1.0 * 8760},  # GWh/yr/GW
 |              )
 |          ],
 |      ),
 |  ]
 |
 |  model = Model(
 |      id="simple-carbon-price",
 |      time_definition=time_definition,
 |      regions=regions,
 |      commodities=commodities,
 |      impacts=impacts,
 |      technologies=technologies,
 |  )
 |  ```
 |  ### From csv
 |
 |  A Model object can also be created from a set of otoole style CSVs as below, using the class
 |  method from_otoole_csv():
 |
 |  ```python
 |  from tz.osemosys import Model
 |
 |  path_to_csvs = "examples/otoole_compat/input_csv/otoole-full-electricity-complete/"
 |
 |  model = Model.from_otoole_csv(root_dir=path_to_csvs)
 |  ```
 |
 |  ### From yaml
 |
 |  Alternatively, a model can be created from a TZ-OSeMOSYS yaml or set of yamls, examples of
 |  which can be found in the tz-osemosys repository.
 |
 |  ```python
 |  from tz.osemosys import Model
 |
 |  path_to_yaml = "examples/utopia/main.yaml"
 |
 |  model = Model.from_yaml(path_to_yaml)
 |  ```
 |
 |  ## Solving a model
 |
 |  Once a model object has been constructed or loaded via one of the above methods, it can be
 |  solved by calling the solve() method.
 |
 |  ```python
 |  from tz.osemosys import Model
 |
 |  path_to_yaml = "examples/utopia/main.yaml"
 |
 |  model = Model.from_yaml(path_to_yaml)
 |
 |  model.solve()
 |  ```
 |
 |  By default, the model will be solved using the first available solver in the list of available
 |  solvers. To specify a solver, pass the name of the solver as a string to the solve() method for
 |  the argument `solver_name` (e.g. `model.solve(solver_name="highs")`).
 |
 |  ### Viewing the model solution
 |
 |  Once the model has been solved, the solution can be accessed via the `solution` attribute of the
 |  model object, which returns an xarray DataSet.
 |
 |  To display all available solution DataArrays within the solution DataSet, run:
 |  ```python
 |  model.solution.data_vars
 |  ```
 |
 |  To view the values of a specific DataArray, such as NewCapacity, run:
 |  ```python
 |  model.solution["NewCapacity"]
 |  ```
 |
 |  This can be converted to a more easily readible format by converting to a pandas DataFrame:
 |  ```python
 |  model.solution["NewCapacity"].to_dataframe().reset_index()
 |  ```
 |
 |  ### Writing the model solution to excel
 |
 |  Writing a specfic DataArray (NewCapacity) to an excel file can be done by running the following:
 |  ```python
 |  model.solution["NewCapacity"].to_dataframe().reset_index().to_excel(
 |      "NewCapacity.xlsx", index=False
 |  )
 |  ```
 |
 |  All DataArrays in the model solution can be written to excel files by running the following:
 |  ```python
 |  for array in model.solution:
 |      model.solution[array].to_dataframe().reset_index().to_excel(
 |          f"{array}.xlsx", index=False
 |      )
 |  ```
 |
 |  Method resolution order:
 |      Model
 |      tz.osemosys.schemas.model.RunSpec
 |      tz.osemosys.schemas.base.OSeMOSYSBase
 |      tz.osemosys.schemas.compat.model.RunSpecOtoole
 |      pydantic.main.BaseModel
 |      builtins.object
 |
 |  Methods defined here:
 |
 |  model_post_init = init_private_attributes(self: 'BaseModel', context: 'Any', /) -> 'None' from pydantic._internal._model_construction
 |      This function is meant to behave like a BaseModel method to initialise private attributes.
 |
 |      It takes context as an argument since that's what pydantic-core passes when calling it.
 |
 |      Args:
 |          self: The BaseModel instance.
 |          context: The context.
 |
 |  read_netcdf(self, path: str | os.PathLike[str])
 |
 |  save_netcdf(self, path: str | os.PathLike[str]) -> None
 |
 |  solve(self, solution_vars: list[str] | str | None = None, solver_options: dict[str, typing.Any] | None = None, **linopy_solve_kwargs: Any) -> tuple[str, str]
 |
 |  ----------------------------------------------------------------------
 |  Class methods defined here:
 |
 |  from_otoole_csv(root_dir, id: str | None = None)
 |
 |  from_yaml(*spec_files)
 |
 |  ----------------------------------------------------------------------
 |  Readonly properties defined here:
 |
 |  objective
 |
 |  solution
 |
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |
 |  __abstractmethods__ = frozenset()
 |
 |  __annotations__ = {'_data': <class 'xarray.core.dataset.Dataset'>, '_l...
 |
 |  __class_vars__ = {'otoole_stems'}
 |
 |  __private_attributes__ = {'_data': ModelPrivateAttr(default=PydanticUn...
 |
 |  __pydantic_complete__ = True
 |
 |  __pydantic_computed_fields__ = {}
 |
 |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'tz.osemosy...
 |
 |  __pydantic_custom_init__ = False
 |
 |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
 |
 |  __pydantic_fields__ = {'commodities': FieldInfo(annotation=List[Commod...
 |
 |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
 |
 |  __pydantic_parent_namespace__ = None
 |
 |  __pydantic_post_init__ = 'model_post_init'
 |
 |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
 |      Model...
 |
 |  __pydantic_setattr_handlers__ = {}
 |
 |  __pydantic_validator__ = SchemaValidator(title="Model", validator=Func...
 |
 |  __signature__ = <Signature (*, otoole_cfg: tz.osemosys.schemas.c...ema...
 |
 |  model_config = {}
 |
 |  ----------------------------------------------------------------------
 |  Methods inherited from tz.osemosys.schemas.model.RunSpec:
 |
 |  compose(self)
 |
 |  composition_validation(self)
 |      Do composition checks ensuring all commodities, impacts, and storage are linked to a
 |      technology.
 |
 |      Additionally, check that reserve_margin is fully defined and that discount rates are in
 |      decimals.
 |
 |  maybe_mixin_discount_rate_idv(self)
 |
 |  maybe_mixin_discount_rate_storage(self)
 |
 |  ----------------------------------------------------------------------
 |  Class methods inherited from tz.osemosys.schemas.model.RunSpec:
 |
 |  cast_values(values: Any) -> Any
 |
 |  ----------------------------------------------------------------------
 |  Class methods inherited from tz.osemosys.schemas.base.OSeMOSYSBase:
 |
 |  backfill_missing(values)
 |
 |  id_delimiter_check(values)
 |      This checks if ids contain ":", which are not allowed due to their incompatibility with
 |      URLs and with the tz-osemosys json_dict_to_dataframe() function.
 |
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from tz.osemosys.schemas.base.OSeMOSYSBase:
 |
 |  __weakref__
 |      list of weak references to the object
 |
 |  ----------------------------------------------------------------------
 |  Methods inherited from tz.osemosys.schemas.compat.model.RunSpecOtoole:
 |
 |  map_datatypes(self, df: pandas.core.frame.DataFrame)
 |
 |  to_dataframes(self) -> Dict[str, pandas.core.frame.DataFrame]
 |      Convert Runspec to otoole style output CSVs and config.yaml
 |
 |      Parameters
 |      ----------
 |      output_directory: str
 |          Path to the output directory for CSV files to be placed
 |
 |  to_model_dataframes(self) -> Dict[str, pandas.core.frame.DataFrame]
 |      Convert RunSpec to otoole style output CSVs, only for parameters created on the model object
 |
 |  to_otoole_csv(self, output_directory)
 |
 |  to_xr_ds(self)
 |      Return the current RunSpec as an xarray dataset
 |
 |      Args:
 |        self: this RunSpec instance
 |
 |      Returns:
 |        xr.Dataset: An XArray dataset containing all data from the RunSpec
 |
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from tz.osemosys.schemas.compat.model.RunSpecOtoole:
 |
 |  otoole_stems = {'DepreciationMethod': {'attribute': 'depreciation_meth...
 |
 |  ----------------------------------------------------------------------
 |  Methods inherited from pydantic.main.BaseModel:
 |
 |  __copy__(self) -> 'Self'
 |      Returns a shallow copy of the model.
 |
 |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
 |      Returns a deep copy of the model.
 |
 |  __delattr__(self, item: 'str') -> 'Any'
 |      Implement delattr(self, name).
 |
 |  __eq__(self, other: 'Any') -> 'bool'
 |      Return self==value.
 |
 |  __getattr__(self, item: 'str') -> 'Any'
 |
 |  __getstate__(self) -> 'dict[Any, Any]'
 |      Helper for pickle.
 |
 |  __init__(self, /, **data: 'Any') -> 'None'
 |      Create a new model by parsing and validating input data from keyword arguments.
 |
 |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
 |      validated to form a valid model.
 |
 |      `self` is explicitly positional-only to allow `self` as a field name.
 |
 |  __iter__(self) -> 'TupleGenerator'
 |      So `dict(model)` works.
 |
 |  __pretty__(self, fmt: 'Callable[[Any], Any]', **kwargs: 'Any') -> 'Generator[Any]' from pydantic._internal._repr.Representation
 |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
 |
 |  __replace__(self, **changes: 'Any') -> 'Self'
 |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by
 |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:
 |
 |  __repr__(self) -> 'str'
 |      Return repr(self).
 |
 |  __repr_args__(self) -> '_repr.ReprArgs'
 |
 |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
 |      Name of the instance's class, used in __repr__.
 |
 |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation
 |      Returns the string representation of a recursive object.
 |
 |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
 |
 |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
 |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
 |
 |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
 |      Implement setattr(self, name, value).
 |
 |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
 |
 |  __str__(self) -> 'str'
 |      Return str(self).
 |
 |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      Returns a copy of the model.
 |
 |      !!! warning "Deprecated"
 |          This method is now deprecated; use `model_copy` instead.
 |
 |      If you need `include` or `exclude`, use:
 |
 |      ```python {test="skip" lint="skip"}
 |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
 |      data = {**data, **(update or {})}
 |      copied = self.model_validate(data)
 |      ```
 |
 |      Args:
 |          include: Optional set or mapping specifying which fields to include in the copied model.
 |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
 |          update: Optional dictionary of field-value pairs to override field values in the copied model.
 |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
 |
 |      Returns:
 |          A copy of the model with included, excluded and updated fields as specified.
 |
 |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
 |
 |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
 |
 |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      !!! abstract "Usage Documentation"
 |          [`model_copy`](../concepts/models.md#model-copy)
 |
 |      Returns a copy of the model.
 |
 |      !!! note
 |          The underlying instance's [`__dict__`][object.__dict__] attribute is copied. This
 |          might have unexpected side effects if you store anything in it, on top of the model
 |          fields (e.g. the value of [cached properties][functools.cached_property]).
 |
 |      Args:
 |          update: Values to change/add in the new model. Note: the data is not validated
 |              before creating the new model. You should trust this data.
 |          deep: Set to `True` to make a deep copy of the model.
 |
 |      Returns:
 |          New model instance.
 |
 |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, exclude_computed_fields: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, fallback: 'Callable[[Any], Any] | None' = None, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
 |      !!! abstract "Usage Documentation"
 |          [`model_dump`](../concepts/serialization.md#python-mode)
 |
 |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
 |
 |      Args:
 |          mode: The mode in which `to_python` should run.
 |              If mode is 'json', the output will only contain JSON serializable types.
 |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
 |          include: A set of fields to include in the output.
 |          exclude: A set of fields to exclude from the output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to use the field's alias in the dictionary key if defined.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          exclude_computed_fields: Whether to exclude computed fields.
 |              While this can be useful for round-tripping, it is usually recommended to use the dedicated
 |              `round_trip` parameter instead.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          fallback: A function to call when an unknown value is encountered. If not provided,
 |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |
 |      Returns:
 |          A dictionary representation of the model.
 |
 |  model_dump_json(self, *, indent: 'int | None' = None, ensure_ascii: 'bool' = False, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, exclude_computed_fields: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, fallback: 'Callable[[Any], Any] | None' = None, serialize_as_any: 'bool' = False) -> 'str'
 |      !!! abstract "Usage Documentation"
 |          [`model_dump_json`](../concepts/serialization.md#json-mode)
 |
 |      Generates a JSON representation of the model using Pydantic's `to_json` method.
 |
 |      Args:
 |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
 |          ensure_ascii: If `True`, the output is guaranteed to have all incoming non-ASCII characters escaped.
 |              If `False` (the default), these characters will be output as-is.
 |          include: Field(s) to include in the JSON output.
 |          exclude: Field(s) to exclude from the JSON output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to serialize using field aliases.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          exclude_computed_fields: Whether to exclude computed fields.
 |              While this can be useful for round-tripping, it is usually recommended to use the dedicated
 |              `round_trip` parameter instead.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          fallback: A function to call when an unknown value is encountered. If not provided,
 |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |
 |      Returns:
 |          A JSON string representation of the model.
 |
 |  ----------------------------------------------------------------------
 |  Class methods inherited from pydantic.main.BaseModel:
 |
 |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
 |
 |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
 |
 |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
 |      Hook into generating the model's JSON schema.
 |
 |      Args:
 |          core_schema: A `pydantic-core` CoreSchema.
 |              You can ignore this argument and call the handler with a new CoreSchema,
 |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
 |              or just call the handler with the original schema.
 |          handler: Call into Pydantic's internal JSON schema generation.
 |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
 |              generation fails.
 |              Since this gets called by `BaseModel.model_json_schema` you can override the
 |              `schema_generator` argument to that function to change JSON schema generation globally
 |              for a type.
 |
 |      Returns:
 |          A JSON schema, as a Python object.
 |
 |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
 |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
 |      only after basic class initialization is complete. In particular, attributes like `model_fields` will
 |      be present when this is called, but forward annotations are not guaranteed to be resolved yet,
 |      meaning that creating an instance of the class may fail.
 |
 |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
 |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
 |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
 |
 |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
 |      any kwargs passed to the class definition that aren't used internally by Pydantic.
 |
 |      Args:
 |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
 |              by Pydantic.
 |
 |      Note:
 |          You may want to override [`__pydantic_on_complete__()`][pydantic.main.BaseModel.__pydantic_on_complete__]
 |          instead, which is called once the class and its fields are fully initialized and ready for validation.
 |
 |  __pydantic_on_complete__() -> 'None'
 |      This is called once the class and its fields are fully initialized and ready to be used.
 |
 |      This typically happens when the class is created (just before
 |      [`__pydantic_init_subclass__()`][pydantic.main.BaseModel.__pydantic_init_subclass__] is called on the superclass),
 |      except when forward annotations are used that could not immediately be resolved.
 |      In that case, it will be called later, when the model is rebuilt automatically or explicitly using
 |      [`model_rebuild()`][pydantic.main.BaseModel.model_rebuild].
 |
 |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
 |
 |  from_orm(obj: 'Any') -> 'Self'
 |
 |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
 |      Creates a new instance of the `Model` class with validated data.
 |
 |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
 |      Default values are respected, but no other validation is performed.
 |
 |      !!! note
 |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
 |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
 |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
 |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
 |          an error if extra values are passed, but they will be ignored.
 |
 |      Args:
 |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,
 |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.
 |              Otherwise, the field names from the `values` argument will be used.
 |          values: Trusted or pre-validated data dictionary.
 |
 |      Returns:
 |          A new instance of the `Model` class with validated data.
 |
 |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation', *, union_format: "Literal['any_of', 'primitive_type_array']" = 'any_of') -> 'dict[str, Any]'
 |      Generates a JSON schema for a model class.
 |
 |      Args:
 |          by_alias: Whether to use attribute aliases or not.
 |          ref_template: The reference template.
 |          union_format: The format to use when combining schemas from unions together. Can be one of:
 |
 |              - `'any_of'`: Use the [`anyOf`](https://json-schema.org/understanding-json-schema/reference/combining#anyOf)
 |              keyword to combine schemas (the default).
 |              - `'primitive_type_array'`: Use the [`type`](https://json-schema.org/understanding-json-schema/reference/type)
 |              keyword as an array of strings, containing each type of the combination. If any of the schemas is not a primitive
 |              type (`string`, `boolean`, `null`, `integer` or `number`) or contains constraints/metadata, falls back to
 |              `any_of`.
 |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
 |              `GenerateJsonSchema` with your desired modifications
 |          mode: The mode in which to generate the schema.
 |
 |      Returns:
 |          The JSON schema for the given model class.
 |
 |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
 |      Compute the class name for parametrizations of generic classes.
 |
 |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
 |
 |      Args:
 |          params: Tuple of types of the class. Given a generic class
 |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
 |              the value `(str, int)` would be passed to `params`.
 |
 |      Returns:
 |          String representing the new class where `params` are passed to `cls` as type variables.
 |
 |      Raises:
 |          TypeError: Raised when trying to generate concrete names for non-generic models.
 |
 |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None'
 |      Try to rebuild the pydantic-core schema for the model.
 |
 |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
 |      the initial attempt to build the schema, and automatic rebuilding fails.
 |
 |      Args:
 |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
 |          raise_errors: Whether to raise errors, defaults to `True`.
 |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
 |          _types_namespace: The types namespace, defaults to `None`.
 |
 |      Returns:
 |          Returns `None` if the schema is already "complete" and rebuilding was not required.
 |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
 |
 |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self'
 |      Validate a pydantic model instance.
 |
 |      Args:
 |          obj: The object to validate.
 |          strict: Whether to enforce types strictly.
 |          extra: Whether to ignore, allow, or forbid extra data during model validation.
 |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.
 |          from_attributes: Whether to extract data from object attributes.
 |          context: Additional context to pass to the validator.
 |          by_alias: Whether to use the field's alias when validating against the provided input data.
 |          by_name: Whether to use the field's name when validating against the provided input data.
 |
 |      Raises:
 |          ValidationError: If the object could not be validated.
 |
 |      Returns:
 |          The validated model instance.
 |
 |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self'
 |      !!! abstract "Usage Documentation"
 |          [JSON Parsing](../concepts/json.md#json-parsing)
 |
 |      Validate the given JSON data against the Pydantic model.
 |
 |      Args:
 |          json_data: The JSON data to validate.
 |          strict: Whether to enforce types strictly.
 |          extra: Whether to ignore, allow, or forbid extra data during model validation.
 |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.
 |          context: Extra variables to pass to the validator.
 |          by_alias: Whether to use the field's alias when validating against the provided input data.
 |          by_name: Whether to use the field's name when validating against the provided input data.
 |
 |      Returns:
 |          The validated Pydantic model.
 |
 |      Raises:
 |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.
 |
 |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, extra: 'ExtraValues | None' = None, context: 'Any | None' = None, by_alias: 'bool | None' = None, by_name: 'bool | None' = None) -> 'Self'
 |      Validate the given object with string data against the Pydantic model.
 |
 |      Args:
 |          obj: The object containing string data to validate.
 |          strict: Whether to enforce types strictly.
 |          extra: Whether to ignore, allow, or forbid extra data during model validation.
 |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.
 |          context: Extra variables to pass to the validator.
 |          by_alias: Whether to use the field's alias when validating against the provided input data.
 |          by_name: Whether to use the field's name when validating against the provided input data.
 |
 |      Returns:
 |          The validated Pydantic model.
 |
 |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
 |
 |  parse_obj(obj: 'Any') -> 'Self'
 |
 |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
 |
 |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
 |
 |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
 |
 |  update_forward_refs(**localns: 'Any') -> 'None'
 |
 |  validate(value: 'Any') -> 'Self'
 |
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from pydantic.main.BaseModel:
 |
 |  __fields_set__
 |
 |  model_extra
 |      Get extra fields set during validation.
 |
 |      Returns:
 |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
 |
 |  model_fields_set
 |      Returns the set of fields that have been explicitly set on this model instance.
 |
 |      Returns:
 |          A set of strings representing the fields that have been set,
 |              i.e. that were not filled from defaults.
 |
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from pydantic.main.BaseModel:
 |
 |  __dict__
 |      dictionary for instance variables
 |
 |  __pydantic_extra__
 |
 |  __pydantic_fields_set__
 |
 |  __pydantic_private__
 |
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from pydantic.main.BaseModel:
 |
 |  __hash__ = None
 |
 |  __pydantic_root_model__ = False
 |
 |  model_computed_fields = {}
 |
 |  model_fields = {'commodities': FieldInfo(annotation=List[Commodity], r...

